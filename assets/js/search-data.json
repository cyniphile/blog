{
  
    
        "post0": {
            "title": "Five Levels Of (Bioinformatics) Programming",
            "content": "Level 1: Python . I want to make the switch from “data science” to bioinformatics. While most of my statistics and machine learning skills transfer pretty seamlessly to this new domain, I’ve also been learning more bioinformatics by doing Rosalind problems. Rosalind is like Project Euler with a biology focus. I started out solving the problems in Python, the language I know best. . For example, in the second Rosalind problem we’re asked to write a function that transcribes DNA to RNA. Here’s my Python solution:1 . # python hand-rolled def transcribe(dna: str) -&gt; str: return &#39;&#39;.join([&quot;U&quot; if char == &#39;T&#39; else char for char in dna]) . . Level 2: Rust . I realized this would be a perfect opportunity to try out Rust, which is supposed to make writing extremely fast code safer and easier. . If You Already Know What Rust Is, Skip This . Rust is a “low-level language with high-level abstractions.” It’s supposed to be as fast and as fine-grained as C, but more “ergonomic” (less code to write because of the said high-level abstractions) and also much safer from bugs. . Rust is fast partially because it’s not garbage collected. Instead, the compiler helps you manually manage memory. To this end it requires you, the programmer, to write some extra bookkeeping annotations that say which functions are using which variables and when (so-called “ownership” with “borrowing” and “lifetimes”). I’ve seen this called “semiautomatic memory management” (as opposed to C/C++ which are fully manual; the compiler doesn’t stop you from making mistakes). This is why people often complain about “fighting the compiler” with Rust: it’s always pointing out inconsistencies in your variable management (in addition to all the usual type errors you get from more typical compilers). That said, once something does compile, you should have a memory-safe, robust, and probably very fast program. . There are also other low-level complexities of the language. For example, there is not one int type but eight, depending on if you want the integer to be signed and how many bits you want to represent it with. One has to understand the basics of stack versus heap memory. Strings are very complicated. And so on. . The Rust book is a great resource for learning the language. Rust has a steep learning curve, but I’ve also not really done low-level programming before, so a lot of the effort for me was learning that. Overall I’ve found Rust is like bowling with the bumpers: it can be maddening to be always bouncing back and forth down the lane, but eventually I always knock some pins over, as opposed to C++ where I’d probably never trust my code to run in a production environment, especially one as correctness-critical as biology. . Rust .transcribe . The Rust implementation of .transcribe is pretty similar to the Python one (especially since I used Python type hints), except for the &amp; borrow notation and the .collect one has to explicitly call on the lazily evaluated .chars iterator. . // rust hand-rolled #[pyfunction] fn transcribe(dna: &amp;str) -&gt; String { dna .chars() .map(|x| if x == &#39;T&#39; { &#39;U&#39; } else { x }) .collect() } . Additionally, I added the decorator-looking #[pyfunction] thing (actually a Rust macro) from the PyO3 Rust package which makes it really easy to use Rust with Python2. You (more or less) just add such a prefix, and then you can call the Rust function from Python like so: . # calling rust functions from python import bio_lib_string_rs dna = &quot;ACTGACTC&quot; bio_lib_string_rs.transcribe(dna) . Since the Rust version is callable from Python, I could easily wrap both implementations in pytest benchmarks for an initial speed test on a ~1000bp DNA string. I got the following results: . Woot. The Rust version is over 17x faster3, including the overhead of parsing the Python DNA string into a Rust string. I also ran a pure Rust benchmark on the same data (no Python involved) and Rust was over 50x faster than Python. . More Thorough Performance Comparisons . Now some of you Pythonistas might be foaming at the mouth and swearing at your screen right now, because the way I implemented transcribe wasn’t very Pythonic. I hand-rolled the following function: . # python hand-rolled def transcribe(dna: str) -&gt; str: return &#39;&#39;.join([&quot;U&quot; if char == &#39;T&#39; else char for char in dna]) . when I could have just used Python’s built-in .replace function: . # python built-in def transcribe_builtin(dna: str) -&gt; str: return dna.replace(&quot;T&quot;, &quot;U&quot;) . Sure, Rust is a lot faster if we compare apples-to-apples implementations of the same algorithm, but that’s not quite fair in this case because you’d never actually use the hand-rolled implementation in Python, or even Rust for that matter (which also has a built-in .replace). So I benchmarked the built-ins as well: . // rust built-in #[pyfunction] fn transcribe_builtin(dna: &amp;str) -&gt; String { dna.replace(&quot;T&quot;, &quot;U&quot;) } . And also the Python numpy package built-in: . # numpy import numpy as np def transcribe_np(dna: str) -&gt; str: return str(np.char.replace(dna, &quot;T&quot;, &quot;U&quot;)) # type: ignore . I also set up some separate benchmarks of the Rust functions called directly in Rust, no Python or PyO3 involved. Here are the results on the 1kbp file: . . The Python built-in .replace function is actually the fastest by far. It’s over twice as fast as my Rust function and the Rust .replace built-in. . This sort of makes sense since Python’s .replace is actually just a highly optimized C function, though it’s still surprising that the Rust .replace built-in is a lot slower4. . The same ranking holds over different sizes of data, though Numpy seems to eventually overcome some fixed initialization overhead. . This plot was made using a perfplot-based Python script, so the pure Rust functions weren’t included. . Actually Speeding Something Up . I decided to try out a more domain-specific bioinformatics task that isn’t already a Python built-in. This next Rosalind problem is to identify reverse palindromes in a DNA sequence, Python answer below:5 . @dataclass class PalindromeLocation: start_index: int length: int def find_reverse_palindromes(seq: str) -&gt; List[PalindromeLocation]: min_len = 4 max_len = 12 locations = [] for i in range(0, len(seq) - min_len + 1): for length in range(min_len, max_len + 1, 2): if i + length &gt; len(seq): continue test_seq = seq[i:(i + length)] if is_reverse_palindrome(test_seq): locations.append( PalindromeLocation(start_index=i + 1, length=length) ) return locations def is_reverse_palindrome(seq: str) -&gt; bool: return seq == reverse_complement_dna(seq) def reverse_complement_dna(dna_seq: str) -&gt; str: return &#39;&#39;.join([dna_base_complement(b) for b in dna_seq[::-1]]) def dna_base_complement(base: str) -&gt; str: if base == &quot;A&quot;: return &quot;T&quot; elif base == &quot;T&quot;: return &quot;A&quot; elif base == &quot;G&quot;: return &quot;C&quot; elif base == &quot;C&quot;: return &quot;G&quot; else: raise Exception(&quot;Non-DNA base &quot;{} &quot; found.&quot;.format(base)) . The Rust implementation is very similar but uses a more functional style (.fold instead of an outer for loop)6. . #[pyclass] pub struct PalindromeLocation { #[pyo3(get, set)] pub start_index: usize, #[pyo3(get, set)] pub length: usize, } #[pyfunction] pub fn find_reverse_palindromes(seq: &amp;str) -&gt; Vec&lt;PalindromeLocation&gt; { let min_len = 4; let max_len = 12; seq.chars() .take(seq.len() - min_len + 1) .enumerate() .fold(Vec::new(), |mut acc, (i, _)| { for length in (min_len..(max_len + 1)).step_by(2) { if i + length &gt; seq.len() { continue; } let test_seq = &amp;seq[i..(i + length)]; if is_reverse_palindrome(test_seq) { acc.push(PalindromeLocation { start_index: i + 1, length, }); } } acc }) } pub fn is_reverse_palindrome(seq: &amp;str) -&gt; bool { seq == reverse_complement_dna(seq) } pub fn reverse_complement_dna(dna_seq: &amp;str) -&gt; String { dna_seq.chars().rev().map(dna_base_complement).collect() } pub fn dna_base_complement(base: char) -&gt; char { match base { &#39;A&#39; =&gt; &#39;T&#39;, &#39;T&#39; =&gt; &#39;A&#39;, &#39;G&#39; =&gt; &#39;C&#39;, &#39;C&#39; =&gt; &#39;G&#39;, _ =&gt; panic!(&quot;Non-DNA base &quot;{} &quot; found.&quot;, base), } } . And I also added a small Python wrapper to map the Rust PalindromeLocation struct to the Python dataclass, which adds more language interface overhead7. . def find_reverse_palindromes_rs(seq: str) -&gt; List[PalindromeLocation]: ps = bio_lib_string_rs.find_reverse_palindromes(seq) return [ PalindromeLocation( start_index=p.start_index, length=p.length ) for p in ps ] . I also made a Python implementation that uses Numpy arrays (see the repo for details). . How did things pan out this time? . . Rust is about 15x faster than base Python, even with all the conversion overhead! Was it worth the effort? I’d say “yes!” Writing these relatively simple Rust functions is frankly pretty easy (though Rust definitely can get a lot harder). The PyO3 crate makes it straightforward to incrementally add the extra “Rust thrust” (new viral hashtag?) when you need it. This wasn’t without paper-cuts or head-scratchers, but if this was for heavily reused code (part of a data pipeline?), it’s well worth the price of implementation.8 . . Level 3: Algebraic Data Types . So far I’ve just represented DNA as strings. This is bad, and here’s an example of why. . pub fn dna_base_complement(base: char) -&gt; char { match base { &#39;A&#39; =&gt; &#39;T&#39;, &#39;T&#39; =&gt; &#39;A&#39;, &#39;G&#39; =&gt; &#39;C&#39;, &#39;C&#39; =&gt; &#39;G&#39;, // Commented out for now... // _ =&gt; panic!(&quot;Non-DNA base &quot;{} &quot; found.&quot;, base), } } . This Rust little function, when given a DNA base, returns the complementary base. Note I had to name it dna_base_complement, because it only works with DNA. If you understand basic biology, you know the output is also DNA (not RNA, or amino acids). However, none of this information is encoded in the logic of the function’s code. . I’ve commented out a line in the code above, and without it, the function actually doesn’t compile. Rust checks pattern matches for exhaustivity, and since any UTF-8 char can be passed into this function, I have to also handle the case where the base argument happens to not be “A”, “C”, “T”, or “G”. . . So I have to uncomment that last line, which is a catch-all case. Now if I somehow give a non-DNA character to our function at runtime, the program will panic (and crash if the panic isn’t handled). Say I accidentally pass in the RNA character “U”…uh oh! Thankfully I can completely eliminate the possibility of this kind of runtime error using Algebraic Data Types or ADTs. . Algebraic data types are simply types composed of other types. There are two main kinds of ADTs: product types and sum types. A product type is an AND group of types: for example tuples, structs, or Python dataclasses. These are pretty obviously useful: sometimes you need to group diversely typed data together under one type, like a user type that has string name AND integer age fields. . The other common ADT, the sum type, was new to me, but I’ve realized it’s perhaps even more powerful and interesting9. A sum type is an XOR group of different types, so an instance can be one (and only one) type out of a set of given options. In Rust you create sum types with the enum keyword. For example: . enum DnaNucleotide { A, C, G, T, } . This defines DnaNucleotide as a new type that can be one of four variants10 A, C, G, or T. Why is this interesting? Well, now I can rewrite my complement function like so: . fn complement(base: DnaNucleotide) -&gt; DnaNucleotide { match base { DnaNucleotide::A =&gt; DnaNucleotide::T, DnaNucleotide::T =&gt; DnaNucleotide::A, DnaNucleotide::C =&gt; DnaNucleotide::G, DnaNucleotide::G =&gt; DnaNucleotide::C, } } . Note I dropped the dna_ prefix from the function name: I know I’m getting the complement of DNA because the base argument is of DnaNucleotide type, and so is the return type. It only accepts DNA, not RNA or “!” or “为” or “🌯”. And if I try to pass in a character I get a compile time error: . . We aren’t even allowed to wire complement up to anything but its proper DNA input. We also get another neat exhaustivity check at compile time if we forget to handle one of the enumerated bases: . . This time I don’t have to add the catch-all _ =&gt; panic!(&quot;Non-DNA base &quot;{} &quot; found.&quot;, base) case because the compiler knows there can only be four different DnaNucleotide variants, and I’ve properly handled all of them. While this example might seem trivial, what about, say, a function from codons to amino acids? If I forget or duplicate one of the $4^3$ codons (like I did below), the compiler tells us! . Note in this example I’ve made use of RnaNucleotide and AminoAcid enums that I defined elsewhere in the code. . This is also useful for easily adapting the software to work with alloproteins (proteins with non-natural amino acids) or artificial base pairs. All I’d have to do is add another symbol to the “AminoAcid” or “DnaNucleotide” enums, and then a bunch of exhaustivity checking compiler errors will pop up wherever I now need to handle the new variant types. . Speed . Does all this organizational overhead make our code perform less efficiently? Well, theoretically it could actually make it more efficient. Strings (in both Rust and Python) are encoded in UTF-8 which uses a minimum of 8-bits per symbol. DNA has only four symbols and so only really needs 2 bits per base. Another consideration is parsing: if our DNA is saved in a file (say FASTA format which just uses character strings), we have to read the file and parse it into our internal enum representation. This means more code to write and more computational overhead. . I wasn’t sure how the trade-off would play out, so I just benchmarked everything using the excellent criterion package for Rust. I compared the original string find_reverse_palindromes function with one that operates on a vector of DnaNucleotide enums. I also timed the ADT/enum version both including the string-to-enum parsing step, and as a pre-parsed version where I only timed the palindrome searching part. Drumroll… . . It looks like Rust’s promise of “zero-cost abstractions” is a lie, we are actually getting negative cost abstractions here! Even including the parsing overhead, the ADT-based version of our function is over twice as fast as the string version. The Rust compiler clearly takes advantage of the enum representation to make some key optimizations (though I couldn’t tell what these optimizations actually are when comparing the emitted assembly and LLVM IR of the two functions. I leave that as an exercise for the reader 😃). . What About Python? . ADTs sort-of exist in Python while using mypy typechecking, which even offers hacky-feeling exhaustivity checks. However, Enum support is not quite ready in PyO3, so it’s not yet possible to call enum-based Rust functions from Python. To use Rust in Python, we’ll just have to wrap our ADT-style function with another function that accepts a string and pre-parses it into a vector of enums: . #[pyfunction] pub fn find_reverse_palindrome_dna(seq: &amp;str) -&gt; Vec&lt;PalindromeLocation&gt; { let seq = DNA::parse_string(seq); find_reverse_palindromes(&amp;seq) } . While this hack unfortunately sequesters all the nice ADT-related type checks to the Rust side of the code, at least it allows us to take advantage of the speed boost of using enums in Python. . . Level 4: Parallelize . So far I’ve been ignoring one of the most important speed factors in modern programming: parallelism. It’s always slightly painful to see my six-core Intel i7 running at, well, 1/6 capacity! . I decided to try out the newish ray package to parallelize my Python code11. The code for finding reverse palindromes ended up being reasonably similar to the single-threaded version, though it requires an extra BATCH_SIZE parameter which needs be tuned to optimally slice up work into chunks: . import ray import functools import operator def find_reverse_palindromes_par(seq: str) -&gt; List[PalindromeLocation]: min_len = 4 max_len = 12 locations = [] ray_seq = ray.put(seq) # type: ignore BATCH_SIZE = 100 @ray.remote # type: ignore def is_palindrome(i: int) -&gt; List[PalindromeLocation]: seq = ray.get(ray_seq) # type: ignore locations_inner = [] for i in range(i, i+BATCH_SIZE): for length in range(min_len, max_len + 1, 2): if i + length &gt; len(seq): # type: ignore continue test_seq = seq[i:(i + length)] # type: ignore if is_reverse_palindrome(test_seq): # type: ignore locations_inner.append( PalindromeLocation(start_index=i + 1, length=length) ) return locations_inner for i in range(0, len(seq) - min_len + 1, BATCH_SIZE): locations.append(is_palindrome.remote(i)) return functools.reduce( # flatten list of list operator.iconcat, ray.get(locations), [] # type: ignore ) . Now let’s run this and take a look at our CPU monitor: . Yeah baby! All six cores fully engaged sir! . Parallelizing the Rust code turned out to be the first case where implementation is actually easier in Rust than in Python thanks to the excellent rayon package: . pub fn find_reverse_palindromes_par(seq: &amp;DNASlice) -&gt; Vec&lt;PalindromeLocation&gt; { let min_len = 4; let max_len = 12; seq.into_par_iter() .take(seq.len() - min_len + 1) .enumerate() .fold(Vec::new, |mut acc, (i, _)| { for length in (min_len..(max_len + 1)).step_by(2) { if i + length &gt; seq.len() { continue; } let test_seq = &amp;seq[i..(i + length)]; if is_reverse_palindrome(test_seq) { acc.push(PalindromeLocation { start_index: i + 1, length, }); } } acc }) .reduce( Vec::new, |a: Vec&lt;PalindromeLocation&gt;, b: Vec&lt;PalindromeLocation&gt;| [a, b].concat(), ) } . It’s as simple as changing .iter to .into_par_iter and adding a reduce function at the end to stitch together all the asynchronously returned results. Of course, it also needed to be wrapped in similar Python→string→enum/ADT wrapper functions to be useable from Python. . So now it’s time for the final showdown. How do all these “levels” compare speed-wise? . Remember these results are all calls from Python. . While both parallel implementations are slower for smaller inputs (as expected), the Python version is much slower, and it eventually returns to being slower than sequential Python. This was because the BATCH_SIZE parameter needed some tuning, and after some tedious brute force experimentation, I ended up finding a slightly better value (that was still slower than single-threaded Rust). However Rust’s rayon performed excellently out of the box thanks to it’s built-in dynamic performance tuning. . It’s neat to see the performance gains for each of our “levels” of code improvement. In the end, I made my code safer, better organized, and faster by nearly two orders of magnitude. The overhead of learning Rust is certainly high, but hey, I’m already over that hump! . . Level 5? . To avoid publication bias, I admit I also tried a “Level 5” improvement by using iterators more heavily. But, well, gather round… . I was discussing this project with a hacker friend who suggested modifying my functions to return iterators instead of vectors. This way, I could chain together various transformation functions lazily and only call .collect when needed. The compiler could then optimize the entire chain of transformations top to bottom instead of being forced to collect into vector at each step. Since I’m a data scientist with a Spark background, this suggestion made a lot of sense. . This is where implementing things in Rust got incredibly tricky, and frankly very unproductive. I had to switch over to Rust’s nightly build to be able to make use of experimental typing features. I had to rewrite one line functions as 25-line home-made iterator implementations. I had to really get in the mud with lifetimes, traits, and generics, leading to function signatures like: . pub fn transcribe&lt;&#39;a&gt;(seq: DnaIter&lt;&#39;a&gt;) -&gt; impl Iterator&lt;Item = RnaNucleotide&gt; + &#39;a where DnaIter&lt;&#39;a&gt;: &#39;a, { seq.map(|b| transcribe_base(&amp;b)) } . In the end, my code was much less clean, though I could have possibly made it cleaner by using performance-sapping dynamic dispatch12. . I should have stopped and benchmarked sooner, but instead I struggled to port the entire set of bioinformatics functions I’d written so far to this iterators based implementation. The entire monstrosity is available here. And yes, in the end, the code was significantly (~10%) slower. See one benchmark below: . . It would have needed to be a lot faster to justify all the extra work and codebase messiness. Given it was pretty hard to find examples of people using this iterator pattern online, I’m guessing it’s pretty much an anti-pattern. The Rust compiler is clearly worse at optimizing code written this way. In the Rust community, there’s a lot of talk about “idiomatic” code, and I see the value. Unless you’re fluent in assembly and compilers (I’m not), just writing Rust idiomatically seems like an important heuristic for also getting performant Rust. In this case, I violated a universal idiom of all programming languages: “if you’re writing lots of complicated code to do simple things, you’re probably doing it wrong.” . I guess 4 levels of improvement was enough… . TL;DR . Rust is faster than Python, but not necessarily for very simple things. | It’s pretty easy to incrementally add fast Rust functions to an existing Python codebase. | Use algebraic data types like enums instead of strings. ADT-based code is cleaner, safer, and faster. | Parallelization is important, and it’s easy(er) to do in Rust. | Benchmark, don’t theorize. “Humans are terrible at guessing about performance!” | Writing Rust simply and idiomatically will probably result in the fastest code (as well as the cleanest). | . Special thanks to @jgavris of rs-git-fsmonitor fame for various tips and pointers on this post. . Notes . DNA sequence data are stored as the coding strand (not the template strand), so “transcription” really does mean “replace T with U” not “find the RNA complement strand” &#8617; . | For a more detailed tutorial see this guide. Installing and using PyO3 had some paper-cuts: . I needed to add a mysterious config to get it to compile on Mac: | The VSCode rust-analyzer has a bug where it shows fake errors in PyO3 macros. | With PyO3 installed, my project began to show some of Rust’s infamous slow compile times (it went from a couple of seconds ~22s). | . &#8617; . | It’s important to use the super-optimized (and slow compiling) --release flag here. Otherwise, Rust compiles using the default fast-compiling/slow-performing --debug setting. Check out the performance difference for the transcribe function:  &#8617; . | Perhaps this is because CPython is compiled with gcc, which can sometimes emit faster instructions than Rust’s LLVM-based compiler. Or perhaps something else; I didn’t look into it too closely. &#8617; . | Yes, I know, this is not the best algorithm. That’s not the point. The point is to compare the same algorithm in Rust and Python. Side note: I wanted to try out Python 3.10’s new pattern matching, but I couldn’t install some dependencies (SciPy), so I had to go back to version 3.9. &#8617; . | This was the first time I ran into not-so-nice problems with PyO3. I started with a Rust implementation nearly identical to the Python one but I ran into a weird GIL deadlock when benchmarking with perfplot (which apparently does some multithreaded stuff). I managed to resolve this by not having any mut or borrowed variables in the function body, but this was a quick hack fix. I have not yet gone deep on the GIL and mutability w.r.t. PyO3. &#8617; . | We could define the Python dataclass purely in Rust, but I wanted to simulate the effect of adding Rust to an existing Python project, where maybe you don’t want to move a class definition to Rust. &#8617; . | Btw, what about PyPy? I didn’t try it because it still just don’t seem ready as a viable CPython alternative for data science. &#8617; . | This talk by Ron Minsky of Jane Street Capital has some really interesting examples of using algebraic data types to write more robust code (using OCaml in the context of securities trading). &#8617; . | In Rust, variants of an enum aren’t actually types, so you can’t so something like fn f(s: DnaNucleotide::A) {}. You also can’t write polymorphic code with enums like so: . enum Nucleotide{ RnaNucleotide, DnaNucleotide, } fn foo(s: Nucleotide) {s.complement();} . even if all the variants in the enum implement a .complement method. Instead you have to do some wrapper/destructuring stuff (which is pretty messy) or you have to use trait bounds like so: . pub trait Nucleotide { fn complement(&amp;self) -&gt; Self; } fn foo(s: impl Nucleotide) {s.complement();} . &#8617; . | I ran into some gotchas, but the tutorials were generally helpful. &#8617; . | I ran into basically every problem listed in this post. &#8617; . |",
            "url": "https://www.lukeschiefelbein.com/blog/programming/rust/biology/2021/12/01/biology-rust.html",
            "relUrl": "/programming/rust/biology/2021/12/01/biology-rust.html",
            "date": " • Dec 1, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "The State That Commits More Election Fraud Than Michigan (By One Popular Metric)",
            "content": ". Note: I have never voted in a Presidential election, and am not registered as a member of any political party . “The 2020 election was so…2020”, that’s the tagline we’ve settled on as a nation. Joe Biden’s margin of victory was paper-thin in key states, often thinner than Trump’s margins last election. Of course, those 2016 results were widely claimed to be suspicious, which lead to an investigation that uncovered interference from (but debunked many widely alleged theories about direct collusion with) Russia. . Margin of Victory in Key States . &nbsp; 2020 2016 . Wisconsin | 0.62% | 0.82% | . Michigan | 2.73% | 0.24% | . Georgia | 0.29% | 5.32% | . Arizona | 0.35% | 3.78% | . Pennsylvania | 0.79% | 0.75% | . Data Source: New York Times Election Maps . This time it’s the same story, with the party tables turned and the focus on internal voter fraud. The Trump campaign has already filed several lawsuits in swing-states alleging election misconduct. Of course, anyone who’s spent time on social media has seen their share of people wondering aloud about the integrity of the election. Meanwhile the New York Times (along with other mainstream media) claims that next-to-zero fraud occurred (which is actually consistent with their 2016 views on the matter). . Given the focus on fraud, this election has been busy for hordes of indie data pundits (like me). Some are making Deep State connections to hacked election machines, often in connection to the so-called Hammer and Scorecard CIA election interference software that we’ve allegedly turned against ourselves. Others are just hunting for oddities and anomalies. One analyst made minor news when he raised over $200k via GoFundMe for investigating voting irregularities, only to have GoFundMe cancel his campaign citing that he was engaging in “attempts to spread misleading information.” . One data investigation that caught my eye in particular (and the eyes of many others) was that of Dr. Shiva Ayyadurai. He claims to have invented email1, ran as a Republican for US senator in MA (but lost in primaries), and has almost 200k YouTube subscribers. His latest hour-long video was about a case of possible election fraud in Michigan. . In the video, Ayyadurai outlines his team’s analysis of the Michigan counties of Oakland, Macomb, and Kent, where voting data behaves “as though an algorithm was there…that’s what we see here” . The video got a quarter-million views in less than 24 hours. Soon investing legend Michael Burry (Chrisian Bale’s character in The Big Short) was retweeting. . Consider these slides. Worth watching Shiva’s entire presentation for proper context, and deciding for yourself. #Election2020results are full of statistical anomalies that do not find easy explanation, but this is one possible explanation. #Question #Election2020 pic.twitter.com/3vpfZzqYUF . &mdash; Michael Burry MD (@michaeljburry) November 11, 2020 (He deleted these tweets soon after this article’s writing) . I was intrigued and went down the rabbit hole myself. To get an idea for Ayyadurai’s thesis, you can watch his video stating at 13:05, but I’ll also explain his setup below. . Straight Ticket Voting: An Electoral Oddity . Ayyadurai’s analysis centers around an odd aspect of Michigan voting: straight ticket (or straight party) voting. In a few states, Michigan one of them, you can skip voting for individual candidates for president, senate, congress, and other downballot offices. Instead, you can just check one box to vote for “The Democratic Party” (or “The Republican Party”), which automatically casts your votes to the Democrat (or Republican) candidates for every office on the ballot. It’s basically a “select all” option. . . Ayyadurai’s team created a data visualization by plotting the difference between the straight-ticket voting compared with the regular candidate-by-candidate voting (which I’ll refer to as “mixed-ticket”, since you can mix which parties you vote for when voting in this way). First, they organized precinct voting data as follows: . Precinct Straight Ticket Votes Overall Votes (Straight and Mixed Ticket) Difference, Overall vs Straight Ticket . precinct 1 | 60% Trump | 68% Trump | 8% | . precinct 2 | 50% Trump | 48% Trump | -2% | . For each precinct in a county, they show (2nd column from the left) what percentage of straight ticket votes went to Trump. Then they calculate how the overall vote went (3rd column from left), and finally look at the difference between the two. They visualize this data with a plot like so (here showing the example data from above): . . Their thesis is that the straight-ticket voting patterns should be similar to the overall voting patterns. So in a given precinct, if 60% of the straight-ticket votes were for Trump, Ayyadurai pretty reasonably theorizes that around 60% of the mixed party votes should also go to Trump, giving us a flat horizontal line in our plot. . However, when Ayyadurai looked at the actual data from several Michigan counties, he found something much different: a steep and highly significant downward trend, implying that the more Republican a precinct is, the more it tended to flip toward Biden. . It looks like his votes counts start getting linearly reduced and if you look at this curve and I’ve looked at lots of curves…anyone of us who’s in the pattern analysis business when you see this…you say something’s up. This is too structured, right? Too perfect. . He’s right: this level of trend is something that anyone who’s done data science usually loves to see: a very (very) strong correlation between two variables. . What’s going on? This puzzled me too at first. Perhaps it’s caused by “Romney Republicans” that don’t like Trump? Well, Ayyadurai has an answer to that too: if Republicans showed a distaste for Trump, we still ought to see a flat chart, just shifted down. Something else is going on, and for Ayyadurai, the only option left to consider is a malicious algorithm. . And remember we’ve talked about it the election systems…they have the feature of being able to manipulate vote counts from one person to another. It’s called a weighted race feature. . Why Are The Most Republican Precincts Flipping Toward Biden? . That problem is, he’s gotten slightly confused about what he’s looking at. We are NOT actually comparing precincts by “how Republican they are”. We are comparing straight-ticket results to overall results. This is a small but very important difference. Why? When someone goes to the polls in Michigan, they first choose to either vote straight-ticket or mixed-ticket. And they don’t pick randomly. This is what’s called a selection bias in data analysis. . The voters that show up to the polls and check the “all Democrats” or “all Republicans” box are, by definition, more partisan voters than the voters that decide to pick and choose between both parties. If a precinct’s straight-ticket votes (the votes from the most partisan voters in the area) go very Trump, then yes, you would expect the definitionally less partisan voters in the area (the mixed-ticket voters) to vote less strongly that way. . But won’t some Biden supporters switch to Trump too? Yes, but not as many, because in a very Republican area Trump would have more to lose and less to gain. Let’s go through a quick example. . Say a precinct has 1000 constituents: 800 Republican, 200 Democrat. If 10% of the Republicans decide to flip, Trump loses 80 votes. If 10% of the Democrats decide to flip, Trump gains 20 votes, for a net loss of 60 votes. Given the selection bias at work, most of these flipping voters are going to do a mixed-ticket vote…if you are a Republican that hates Trump, you probably still want to vote GOP for Senate, etc. . . Ayyadurai would say here, 60 votes got moved to Biden. But it’s actually just that mixed-ticket voters are less likely (by definition) to vote with precinct norms, and will tend to move overall results back towards the center. . All of this works the same way for more Democratic precincts; just do the same math but switch “Republican” and “Democrat”, and “Trump” and “Biden”. And if a precinct is split 50/50, there flipping votes net to zero. How does all this look on the precinct plots we’ve been looking at? . . It’s a nice downward sloping line. I’ve only done three data points, but you can see how the rest of the line fills in depending on how Republican or Democrat a precinct is. You can get a steeper line by increasing the percentage of mixed voters that flip (I used a rate of 20% in the example above), or shift the line up or down by making the flip percentage assymentical (e.g. 20% of Republicans flip, but only 10% of Democrats do). Add in some random variation, and this is exactly what we’re seeing in Dr. Shiva’s Michigan chart. It’s theoretically totally normal2. . Do Real Elections Actually Work This Way? . So we’ve got ourselves a theory about why these downward trends might exist, no fraud required. Let’s now do what Dr. Shiva didn’t do and look at more data. If our theory is right, we’d expect most counties to show this downward trend, and if Dr. Shiva’s is right, this downward trend should almost never appear. . Remember, only a few states do straight-ticket voting, and it turned out to be either quite a pain or impossible to get at their data. Ok.gov didn’t seem to work at all, much less have a detailed voting records API. Yikes. . Of course, we do know Michigan’s data is available, so lets take the first minimal step of verification Dr. Shiva didn’t bother to take: look at the same “suspicious” counties in the 2016 election, when Trump won Michigan. Is 2020 really an anomaly? Let’s look at Oakland county in 2016: . . It’s the same super statistically significant downward linear trend. It’s not as steep as in 2020, but still equally “suspicious” according to Ayyadurai’s theory. What about the following counties: . . Do these charts get your pattern researcher taste-buds salivating? Ready to take to the Twitters and yell fraud? Before you do, I should say this is data from Randoph, Jackson, Walker, Autauga, Geneva, and Fayette counties…in Alabama (2016 election)3. This is obviously not the first state that comes to mind when you think of election hacking targets; the state hasn’t voted for a Democrat president since Jimmy Carter in ‘76. . I admit, I cherry-picked some of the “worst” counties above, but the same trend holds throughout. Running Ayyadurai’s analysis on all Alabama counties in 2016, 70% of them showed a negative, statistically significant slope (in other words β &lt; 0 and p &lt; 0.05). In fact, only 13 of the 67 counties were “normal” by Dr. Shiva’s definition, showing no significant trend either way. . So…Now What? . Now we are at a crossroads. We’ve got a theory for why such patterns could exist completely legitimately, and the data shows these “suspicious” patterns seem to be the norm. . . I’d go with “there was no fraud” (at least of this kind). Dr. Shiva essentially cooked up a graph of “do mixed-party voters vote less partisan than fully partisan voters?” It’s almost a tautology, and if considered carefully, you’d expect a trend. I don’t know if my explanation is 100% correct, but it’s certainly much better supported by the data than Dr. Shiva’s theory that “trends are anomalous and signify fraud.” . Is Dr. Shiva lying to us then? Probably not. The selection bias he overlooked is easy to miss, and even the best data gurus out there make mistakes in identifying them. . Was Dr. Shiva doing good science and just happened to mess up? No, absolutely not. He and his team didn’t do even the most basic checks to support their theory, i.e. the checks I did above with 2016 election data (by myself in less than a day’s work). Even so, they decided to go ahead and claim there was a clear sign of fraud in Michigan, and publish this to their 200k trusting subscribers. Nothing could be more scientifically irresponsible, especially for a man that claims over and over again to be following the principles of science. Now I’m starting to wonder…did he really invent email? . Code and data used to generate this analysis can be found on Github. . 1. The invention of email is generally credited to Ray Tomlinson around 1970, though Ayyadurai does hold the first copyright to the term dated 1982.↩ . 2. We are making a couple of big assumptions here: 1) that the ratio of split-ticket/mixed-ticket votes is uncorrelated with a precinct&#39;s party leaning. 2) that the proportion of voters who flip is uncorrelated with a precinct&#39;s party leaning. If either assumption is violated in the right way, you could see flat graphs like Dr. Shiva is showing. Ultimately, we simply need to look to the data to see if graphs with lots of slope are the norm or not.↩ . 3. Alabama was the only state I could find with both straight-ticket voting and (sort of) readily available voting data. 2020 data was not yet available at the time of this writing. If you find more, let me know!↩ .",
            "url": "https://www.lukeschiefelbein.com/blog/election%20fraud/politics/2020/11/12/voter-fraud.html",
            "relUrl": "/election%20fraud/politics/2020/11/12/voter-fraud.html",
            "date": " • Nov 12, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "The Slant Fueling The Abortion War Must End",
            "content": ". Election time is upon us and abortion is both as important and as divisive as ever. The debate over Trump’s nomination of Amy Coney Barret to the Supreme Court revolved heavily around her probable pro-life1 stance. Meanwhile, in the first presidential debate, Joe Biden explicitly left open the possibility of packing the court in response. . Abortion comes with such a permissive license to righteous anger that most people avoid the festering topic. No wonder a Gallup poll indicates that in the past 25 years the American people have only gotten more divided on the issue, of late jittering around a 50-50 split between pro-life and pro-choice. Facebook feeds are crawling with memes about Bible-thumping, misogynistic white men, or organ harvesting Mengeles at Planned Parenthood. In the abortion debate, once you choose a side, the 150 million people in this country with the opposing view suddenly become some mix of stupid and Satan. . . Like all politics, the issue of abortion has suffered from the mainstream media polarization described so well in Matt Taibbi’s book Hate Inc. The book’s thesis is simple: hate sells. Rage is no longer just a toxic byproduct of our media; it’s the new unnatural life-blood. Now most publications have morphed from forums of fruitful public discourse into profitable echo chambers. . &quot;We live in a time of incredible political division... It’s become difficult to have an argument in the traditional sense. People with differing opinions are often no longer even working from the same commonly-accepted set of facts.&quot; https://t.co/PBREDO6vgd . &mdash; Matt Taibbi (@mtaibbi) September 19, 2020 Abortion is perhaps the ultimate case study of this communication breakdown. There’s no definitive answer to the issue’s fundamental question “when does a fetus become human?”, however abortion “debate” rarely goes so far as to discuss its own fundamental crux. This couldn’t have been illustrated more perfectly in the 2020 vice-presidential debate, with Kamala Harris proudly showing support for “for a woman’s right to make a decision about her own body” while Mike Pence “couldn’t be more proud to serve as vice president to a president who stands without apology for the sanctity of human life.” . Note that this missed connection comes with a district difference in terminology: “make a decision” vs “sanctity of life”. The abortion debate is riddled with such partisan wordplay that reflects each group’s very well-intentioned goals (women’s health vs fetal rights), but they also embody not-so-subtle digs at their opponents. It’s not even possible to reference the parties by name without stirring controversy. If you’re opposed to the “Pro-life” movement, as it calls itself, does that mean you are “not pro-life”? This sounds strange, and so the term “anti-abortion” is used instead, at least by detractors of the movement. By using one set of terminology you unmistakably identify your “side” and immediately either ingratiate yourself with, or aggravate, your audience. . For example this podcast in the New York Times: “An Anti-Abortion Leader on Trump’s Supreme Court Battle” (the title was later changed). A pro-life advocate couldn’t even get past the first two words of the title without feeling slant. . Being a data scientist, I decided to investigate usage of this slanted terminology in a more quantitative way. Knowing that certain terms like “right to life” or “reproductive rights” are almost exclusively partisan and rarely context-dependent, I decided to compile a list of such terms and do a mass search for them in thousands of recent abortion-related news articles (2732 to be exact). By assigning each slanted term a certain weight (“right-to-choose” slants pro-choice, “sanctity of life” slants pro-life) and counting them up, we can uncover which publications lean which way and how strongly. I made the results into an interactive plot below, where you can compare slant across publications and individual articles. You can also customize how terms are weighted based on your personal perception. If you have ideas for other partisan terms, post them in the comments below and I’ll try to add them to the visualization. While this setup is certainly simple2, it nonetheless provides a reasonable high-level picture of the bias extant in journalism today. . interactive chart removed temporarily . Few publications are balanced, and some of the most mainstream papers are very heavy on pro-choice rhetoric. For example, only 25% of articles from the New York Times used a net right-of-center word choice. The Washington Post was much more balanced, and the Bismarck Tribune (from pro-life North Dakota) was extremely right-leaning in its relatively small sample of articles (click on the “Scatter Plot” option to see individual articles). . While partisan writing might function as a call-to-arms for ideological battle, “ideological battle” is an oxymoronic term. The rational brain is suppressed in confrontation, making it almost physically impossible to change a person’s mind if they sense an attack. The “winner” of such a “battle” is just the one with that last word, not the one who spread his or her message successfully. Is it better to incrementally rally the troops to the polls, or to flip the vast mother-lode of votes in the opposition? . Take the mantra “my body, my choice”. It’s easy to chant and rings proudly of a struggle for individual freedom over the implied oppressive patriarchy. And it misses the point. “It’s not a choice, it’s a child” is the memorized pro-life rebuttal. The pro-life movement is not a cabal of men in Colonel Sanders attire meeting in secret cigar lounges to strategize the next move in white male world dominance. While the religious and traditional culture that is correlated with a pro-life stance is sometimes frustratingly sexist, it’s a causation fallacy to conclude such sexism is fundamental to being pro-life. According to the same Gallup Poll, 41% of women, 24% of Democrats, and 34% of those who “seldom or never” attend religious services self-describe as “pro-life”–substantial minorities. . But above all, attempts to “prove” that the pro-life movement is hatefully misogynistic are worse than useless: they are inflammatory. Ditto for the pro-life movement’s penchant for portraying pro-choicers as murderous eugenicists3 or irresponsible sluts. Humans generally believe themselves to be good people and hold their beliefs for what they perceive as good reasons. Declaring either side (tens of millions of Americans) to be stupid and evil is simplistic and displays a gross lack of empathy, a fundamental quality needed for effective debate and negotiation according to master negotiator Chris Voss. Conversion requires deep trust in the converter; it’s the only way to bypass the deeply instinctual fight-or-flight response that is normal when one’s basic ideals are challenged. . Not every abortion advocate is a screaming nihilist femmenismo with 6-inch gauge earrings (though alt-right Twitter is fond of portraying them as such). And they are not “anti-life” but pro-life with a focus on women’s health. The outcomes of abortion can be enormously beneficial both for women4 and their families (by avoiding the obvious physical, emotional, and economic trauma that go with both childbirth) and society at large. The cost is ending the existence of a pre-sentient being. Or at least usually pre-sentient. . Ultimately, the moral reasonableness of abortion goes up closer to conception, a fact that pro-lifers won’t admit. And the reasonableness of abortion goes down the closer to birth, a fact pro-choicers won’t admit. This idea of incrementalism was fairly, though crudely, expressed by Josh Zepps on the Joe Rogan podcast: . [abortion has] become so polarized in the United States that both positions are bullshit, and people on both sides know that both positions are bullshit. It’s bullshit to say that it is “just a women’s health issue and has no ethical implications whatsoever” even when it’s, as you say, about cutting a woman open at nine months and stabbing the embryo in the head5. It’s also bullshit to say that the instant an egg is fertilized, that is a person that should have all of the rights to life that an adult should have and that it’s murder kill a blastocyst that’s smaller than the size of the head of a pin. Both positions are stupid. This is an incremental situation. . . Polls show that nearly 60% of Americans are fine with first-trimester abortions, even though only 46% say they are pro-life. Conversely, only 13% of respondents thought that abortion should be legal in the last trimester. Intuitively, this makes sense: early on the fetus is tiny, doesn’t look that human, and most importantly, can’t feel pain until about 24 weeks gestation. It’s easy to see why pro-life rhetoric often revolves around late-term abortions, a favorite tack of Trump himself. . Biden and Democrats just clarified the fact that they are fully in favor of (very) LATE TERM ABORTION, right up until the time of birth, and beyond - which would be execution. Biden even endorsed the Governor of Virginia, who stated this clearly for all to hear. GET OUT &amp; VOTE!!! . &mdash; Donald J. Trump (@realDonaldTrump) October 6, 2020 While only a small minority (around 1%) of abortions are later term (post 21 weeks gestation) and the practice is restricted in many states, abortions are indeed federally legal up to the moment of birth for any reason (a system much less restrictive than that of most European countries). Additionally, the vast majority of these later-term abortions are not for health reasons of the mother or fetus. While women seeking late-term abortions usually have understandable motives for not getting one sooner (such as lack of access, lack of money and insurance, or recent domestic abuse) this does not erase the fact that a life is being ended that is alarmingly human. Interviewed in a Science Vs podcast, one abortion doctor described the process of “dilation and extraction” (known as “partial-birth abortion” in pro-life lingo) in gory detail, and that “those posters that anti-abortion groups hold around abortion clinics [link possibly NSFW], those photos in them can actually be pretty accurate.” Is it really so crazy to be very uneasy with this? When is it right to inflict pain that you cannot feel, to stop a heart that is not yours, on an obviously human form? Is a big quality-of-life improvement a good enough reason? . For example, families that have children with disabilities can have an increased risk of divorce and increased financial struggle, and disabled children also put a huge financial load on their communities for special education programs and services. From an economic and quality of life perspective, it’s a no-brainer to “terminate” this burden. Now, most pro-choice folks agree “termination” after birth is not morally acceptable at all, but pro-lifers justifiably see the two cases as the same thing. After all, the only difference is a few inches out of the birth canal. . Given the intense moral quandary, is it really beneficial to the pro-choice movement (or even morally sound in general) to die on the hill of federally unrestricted late-term abortion? Conversely, should pro-lifers be willing to die on the hill of limiting access to early-term abortion? While many hold religious beliefs that life is sacred from conception, even if it is just a few cells, is that a reasonable belief to impose on society at large? Could early-term abortions be closer to “a sin that’s legal” like contraception6? . These are the questions that should be discussed instead of simply claiming moral high-ground a priori and then shaming our opponents for not doing so also. The resulting lack of trust has left us ramming legislation down each other’s throats to the beat of partisan power cycles, always pushing for as much as possible so that as much as possible remains after the other side gets its shot at claw-backs. . Remember, Galileo, “the father of modern science”, wasn’t imprisoned for simply advocating that the earth revolves around the sun, which was counter to Catholic teaching at the time. It was because the book he wrote on the subject used slanted language that offended the Pope, who quickly banned the book and put Galileo under house arrest. Only 400 years later did the Church finally admit fault. How much sooner could this have been resolved had Galileo been more tactful, even though he was right? . Likewise, if we drop contentious rhetoric and meme warfare from our abortion debate and adopt an atmosphere of trust via “steel man” argumentation, perhaps we could soon be in a state similar to Western Europe…where people aren’t screaming at each other about abortion nearly as much. . 1. Even using the term “pro-life” (instead of “anti-abortion”) can be seen as political and triggering. We’ll get to this in detail.↩ . 2. Data Notes. This is a visualization and is not meant to present scientific fact. As Henry Clay said, “Statistics are no substitute for judgment”. Data was sourced from ProQuest (via the New York Public Library) by doing a keyword search on US-based news articles that contained the word “abortion” at least twice, to filter out those that reference abortion only in passing (e.g. celebrity gossip). Some publications (e.g. Fox News, HuffPost) either are not in the ProQuest database or don’t provide access to full article text, so they aren’t represented in this dataset. I merged certain closely related publications under one label, e.g. New York Times and New York Times Magazine. Partisan terms were searched for using regular expressions, so &quot;pro life&quot; and &quot;Pro-life&quot;, etc. are all matched. Source code is available on Github. There are of course some cases where the usage of these slant terms does not reflect the author’s bias, for example when the author quotes someone else or when referenced organization names include slant terms (e.g. The National Right to Life Committee). This is a limitation of this type of analysis, but not, I think, a fatal one, as even these references still in some way present the rhetoric of the other side. ↩ . 3. Though it is true Planned Parenthood founder Margaret Sanger supported eugenics, the vast majority of pro-choice advocates today most-likely would be strongly opposed to such ideas.↩ . 4. The pro-life camp often asserts there are a myriad of health risks that come with abortion, especially mental health risks, though there is little-to-no evidence to support this.↩ . 5. Fact check: the procedure for late-term abortion (dilation and extraction) does not actually involve cutting the women open, but it does involve puncturing the fetal head “using scissors or another sharp instrument”. ↩ . 6. In fact, &quot;Some prominent theologians, such as John Chrysostom and Thomas Sanchez, believed that post-quickening [late term] abortion was less sinful than deliberate contraception.&quot;↩ .",
            "url": "https://www.lukeschiefelbein.com/blog/abortion/politics/2020/10/20/abortion.html",
            "relUrl": "/abortion/politics/2020/10/20/abortion.html",
            "date": " • Oct 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "I’m interested in a lot of things. I’ve written a couple movies, news articles, electronic music, and code (usually for data science). . This website is powered by fastpages. .",
          "url": "https://www.lukeschiefelbein.com/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  
      ,"page6": {
          "title": "Subscribe",
          "content": "",
          "url": "https://www.lukeschiefelbein.com/blog/subscribe/",
          "relUrl": "/subscribe/",
          "date": ""
      }
      
  

  

  
  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://www.lukeschiefelbein.com/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}